{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e0ee862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, django\n",
    "os.environ.setdefault('DJANGO_SETTING_MODULE', 'deep-diary.settings')\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"  # 不增加这个就会报异步错误\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54cb8eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.models import Img\n",
    "from face.models import Face, FaceAlbum\n",
    "from insightface.app import FaceAnalysis\n",
    "import numpy as np\n",
    "from deep_diary.settings import FACE_ROOT, FACE_INFO_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d957239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_people_fts(name):\n",
    "    faces = Face.objects.filter(det_method=True, name=name)\n",
    "#     print(faces)\n",
    "    fts = np.array([])\n",
    "    for i in range(len(faces)):\n",
    "        fc_info = np.load(faces[i].face_info.path, allow_pickle=True)\n",
    "        ft = fc_info.item().normed_embedding.reshape(1, -1)\n",
    "#         print(ft.shape)\n",
    "        fts=ft if i==0 else np.concatenate((fts, ft), axis=0)\n",
    "\n",
    "    if fts.ndim == 2:  # fts 有数据，ndim是2\n",
    "        cft = fts.mean(axis=0).reshape(1, -1)  # 将数组a转化为行向量\n",
    "        return fts, cft\n",
    "    else: # fts 无数据，ndim是1\n",
    "        return None, None\n",
    "        \n",
    "\n",
    "# fts, cft = get_people_fts('blue')\n",
    "# print(fts.ndim)\n",
    "# print(cft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a2ad4c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_calc_feats(face):\n",
    "    if not face.face_info:\n",
    "        return\n",
    "    info_path = face.face_info.path\n",
    "    fc_info = np.load(info_path, allow_pickle=True)\n",
    "    ft = fc_info.item().normed_embedding.reshape(1, -1)\n",
    "    \n",
    "    fold = os.path.dirname(face.face_info.path)  # 保存该人的所有人脸特征\n",
    "    all_fts_pth = os.path.join(fold, 'all_feats.txt')\n",
    "    center_fts_pth = os.path.join(fold, 'center_feats.txt')\n",
    "    if os.path.exists(all_fts_pth):\n",
    "        all_fts = np.loadtxt(all_fts_pth, delimiter=',', dtype=float, skiprows=0, comments='#')  # 加载现有的所有人脸特征\n",
    "        if all_fts.ndim == 1:  # 如果是一维数据，则转换成行向量\n",
    "            all_fts = all_fts.reshape(1, -1)\n",
    "        print(f'INFO all_fts shape is {all_fts.shape}, fc_info.normed_embedding shape is {ft.shape}')\n",
    "        new_all_fts = np.concatenate((all_fts, ft), axis=0)\n",
    "    else:\n",
    "        new_all_fts = ft\n",
    "    np.savetxt(all_fts_pth, new_all_fts, delimiter=',', fmt='%.4f')  # 保存该人的所有人脸特征\n",
    "\n",
    "    center_fts = new_all_fts.mean(axis=0).reshape(1, -1)   #将数组a转化为行向量\n",
    "    np.savetxt(center_fts_pth, center_fts, delimiter=',', fmt='%.4f')  # 保存该人中心特征向量，后续改为网络模型计算中心特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed93f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_fts():\n",
    "    names = []  # 保存所有人脸名字\n",
    "\n",
    "    albums = FaceAlbum.objects.filter(is_has_feat=True)\n",
    "#     print(albums)\n",
    "    all_fts = np.array([])\n",
    "    for i in range(len(albums)):\n",
    "        # names.append(album.name)\n",
    "\n",
    "        fts, cft = get_people_fts(albums[i].name)\n",
    "        if fts is not None:\n",
    "            names = np.append(names, albums[i].name)\n",
    "            all_fts=cft if i==0 else np.concatenate((all_fts, cft), axis=0)\n",
    "    return names, all_fts\n",
    "\n",
    "# names, all_fts = get_all_fts()\n",
    "# print(f'INFO names is {names}')\n",
    "# print(f'INFO all_fts is {all_fts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1685281c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "INFO names is allison\n",
      "INFO all_fts.shape is (2, 512)\n",
      "INFO sims is [0.07146305]\n",
      "INFO idx is 1\n",
      "INFO name is mum, sim is [0.99995539]\n",
      "INFO names is mum\n",
      "INFO all_fts is [0.99995539]\n"
     ]
    }
   ],
   "source": [
    "def get_face_name(ft, based='os'):\n",
    "    if based == 'os':\n",
    "        combined_fts_pth = os.path.join(FACE_INFO_ROOT, 'combined_feats.txt')\n",
    "        names_pth = os.path.join(FACE_INFO_ROOT, 'names.txt')\n",
    "        if os.path.exists(combined_fts_pth):\n",
    "            all_fts = np.loadtxt(combined_fts_pth, delimiter=',', dtype=float, skiprows=0, comments='#')  # 加载现有的所有人脸特征\n",
    "            if all_fts.ndim == 1:  # 如果是一维数据，则转换成行向量\n",
    "                all_fts = all_fts.reshape(1, -1)\n",
    "        if os.path.exists(names_pth):\n",
    "            names = np.loadtxt(names_pth, delimiter=',', dtype=str, skiprows=0, comments='#')  # 加载现有的所有人名\n",
    "            print(names.shape)\n",
    "\n",
    "    if based == 'database':\n",
    "        names, all_fts = get_all_fts()  # 得到所有的人名和中心向量\n",
    "\n",
    "    print(f'INFO names is {names[0]}')\n",
    "    print(f'INFO all_fts.shape is {all_fts.shape}')\n",
    "\n",
    "    sims = np.matmul(all_fts, ft.T)\n",
    "    print(f'INFO sims is {sims[0]}')\n",
    "    idx = sims.argmax()\n",
    "    print(f'INFO idx is {idx}')\n",
    "    print(f'INFO name is {names[idx]}, sim is {sims[idx]}')\n",
    "    return names[idx], sims[idx]\n",
    "\n",
    "\n",
    "name='mum'\n",
    "face = Face.objects.filter(det_method=True, name=name).first()\n",
    "ft = np.load(face.face_info.path, allow_pickle=True)\n",
    "ft = ft.item().normed_embedding.reshape(1, -1)  # 得到特征向量\n",
    "# print(f'INFO ft.shape is {ft}')\n",
    "name,sim =  get_face_name(ft)\n",
    "\n",
    "    \n",
    "print(f'INFO names is {name}')\n",
    "print(f'INFO all_fts is {sim}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4417571",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'center_feats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcenter_feats\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose()\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      2\u001b[0m sims \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(all_feats, center_feats\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(sims\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'center_feats' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(center_feats.transpose().shape)\n",
    "sims = np.matmul(all_feats, center_feats.T)\n",
    "print(sims.shape)\n",
    "print(sims)\n",
    "\n",
    "new_all_feats=np.concatenate((all_feats,all_feats),axis=0)\n",
    "print(new_all_feats.shape)\n",
    "new_center_feats=np.concatenate((center_feats,center_feats),axis=0)\n",
    "print(new_center_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d59347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO name is allison, face_feat is D:\\BlueDoc\\deep_diary\\media\\face_info\\allison\\center_feats.txt\n",
      "INFO name is mum, face_feat is D:\\BlueDoc\\deep_diary\\media\\face_info\\mum\\center_feats.txt\n",
      "INFO name is mothers, face_feat is D:\\BlueDoc\\deep_diary\\media\\face_info\\mothers\\center_feats.txt\n",
      "INFO name is susan, face_feat is D:\\BlueDoc\\deep_diary\\media\\face_info\\susan\\center_feats.txt\n"
     ]
    }
   ],
   "source": [
    "albums = FaceAlbum.objects.filter(is_has_feat=True)\n",
    "for album in albums:\n",
    "    print(f'INFO name is {album.name}, face_feat is {album.face_feat.path}')\n",
    "#     center_feats = np.loadtxt(os.path.join(fold,'center_feats.txt'),  delimiter=',', dtype=float, skiprows=0, comments='#').reshape(1,-1)\n",
    "# print(all_feats.ndim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ded92ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "766e515f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO combined_fts_pth do not existed, creating now...\n",
      "INFO names is ['allison', 'mum', 'mothers', 'susan'], feats is (4, 512)\n"
     ]
    }
   ],
   "source": [
    "    names = []  # 保存所有人脸名字\n",
    "\n",
    "    albums = FaceAlbum.objects.filter(is_has_feat=True)\n",
    "    combined_fts_pth = os.path.join(FACE_INFO_ROOT, 'combined_feats.txt')\n",
    "    names_pth = os.path.join(FACE_INFO_ROOT, 'names.txt')\n",
    "    all_fts = np.zeros((1, 512))\n",
    "    print(f'INFO combined_fts_pth do not existed, creating now...')\n",
    "\n",
    "    for album in albums:\n",
    "        names.append(album.name)\n",
    "        center_ft = np.loadtxt(album.face_feat.path, delimiter=',', dtype=float, skiprows=0,\n",
    "                               comments='#').reshape(1, -1)\n",
    "        if all_fts.max() == 0:  # 初始化状态\n",
    "            all_fts = center_ft\n",
    "        else:\n",
    "            all_fts = np.concatenate((all_fts, center_ft), axis=0)\n",
    "    print(f'INFO names is {names}, feats is {all_fts.shape}')\n",
    "\n",
    "    np.savetxt(combined_fts_pth, all_fts, delimiter=',', fmt='%.4f')  # 保存所有人脸特征\n",
    "    np.savetxt(names_pth, names, delimiter=',', fmt='%s')  # 保存所有人对应人名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35e1d5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allison\n"
     ]
    }
   ],
   "source": [
    "album = albums = FaceAlbum.objects.filter(name='allison').first()\n",
    "print(album.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e3612d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_combined_feats():  # 保存所有人脸的中心特征\n",
    "\n",
    "    names = []  # 保存所有人脸名字\n",
    "\n",
    "    albums = FaceAlbum.objects.filter(is_has_feat=True)\n",
    "    combined_fts_pth = os.path.join(FACE_INFO_ROOT, 'combined_feats.txt')\n",
    "    names_pth = os.path.join(FACE_INFO_ROOT, 'names.txt')\n",
    "    all_fts = np.zeros((1, 512))\n",
    "    print(f'INFO combined_fts_pth do not existed, creating now...')\n",
    "\n",
    "    for album in albums:\n",
    "        names.append(album.name)\n",
    "        center_ft = np.loadtxt(album.face_feat.path, delimiter=',', dtype=float, skiprows=0,\n",
    "                               comments='#').reshape(1, -1)\n",
    "        if all_fts.max() == 0:  # 初始化状态\n",
    "            all_fts = center_ft\n",
    "        else:\n",
    "            all_fts = np.concatenate((all_fts, center_ft), axis=0)\n",
    "    print(f'INFO names is {names}, feats is {all_fts.shape}')\n",
    "\n",
    "    np.savetxt(combined_fts_pth, all_fts, delimiter=',', fmt='%.4f')  # 保存所有人脸特征\n",
    "    np.savetxt(names_pth, names, delimiter=',', fmt='%s')  # 保存所有人对应人名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3a4cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_combined_feats(album):  # 保存所有人脸的中心特征\n",
    "    combined_fts_pth = os.path.join(FACE_INFO_ROOT, 'combined_feats.txt')\n",
    "    center_ft = np.loadtxt(album.face_feat.path, delimiter=',', dtype=float, skiprows=0,\n",
    "                           comments='#').reshape(1, -1)\n",
    "\n",
    "    if os.path.exists(combined_fts_pth):\n",
    "        all_fts = np.loadtxt(combined_fts_pth, delimiter=',', dtype=float, skiprows=0, comments='#')  # 加载现有的所有人脸特征\n",
    "        if all_fts.ndim == 1:  # 如果是一维数据，则转换成行向量\n",
    "            all_fts = all_fts.reshape(1, -1)\n",
    "        all_fts = np.concatenate((all_fts, center_ft), axis=0)\n",
    "        print(f'INFO all_fts already existed, the shape is {all_fts.shape}')\n",
    "    else:\n",
    "        all_fts = center_ft\n",
    "        print(f'INFO combined_fts_pth do not existed, creating now...')\n",
    "\n",
    "    names_pth = os.path.join(FACE_INFO_ROOT, 'names.txt')\n",
    "    if os.path.exists(names_pth):\n",
    "        names = np.loadtxt(names_pth, delimiter=',', dtype=str, skiprows=0, comments='#')  # 加载现有的所有人脸特征\n",
    "    else:\n",
    "        names = []\n",
    "    names = np.append(names, album.name)\n",
    "    print(f'INFO names is {names}')\n",
    "\n",
    "    np.savetxt(combined_fts_pth, all_fts, delimiter=',', fmt='%.4f')  # 保存所有人脸特征\n",
    "    np.savetxt(names_pth, names, delimiter=',', fmt='%s')  # 保存所有人对应人名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41fc98f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO all_fts already existed, the shape is (3, 512)\n",
      "INFO names is ['allison' 'allison' 'allison']\n"
     ]
    }
   ],
   "source": [
    "album = FaceAlbum.objects.filter(name='allison').first()\n",
    "update_combined_feats(album)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce69a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyexiv2 import Image as Image_pyexiv2\n",
    "import cv2 as cv\n",
    "\n",
    "# encoding: utf-8\n",
    "def compute_IOU(rec1, rec2):\n",
    "    \"\"\"\n",
    "    计算两个矩形框的交并比。\n",
    "    :param rec1: (x0,y0,x1,y1)      (x0,y0)代表矩形左上的顶点，（x1,y1）代表矩形右下的顶点。下同。\n",
    "    :param rec2: (x0,y0,x1,y1)\n",
    "    :return: 交并比IOU.\n",
    "    \"\"\"\n",
    "    left_column_max = max(rec1[0], rec2[0])\n",
    "    right_column_min = min(rec1[2], rec2[2])\n",
    "    up_row_max = max(rec1[1], rec2[1])\n",
    "    down_row_min = min(rec1[3], rec2[3])\n",
    "    # 两矩形无相交区域的情况\n",
    "    if left_column_max >= right_column_min or down_row_min <= up_row_max:\n",
    "        return 0\n",
    "    # 两矩形有相交区域的情况\n",
    "    else:\n",
    "        S1 = (rec1[2] - rec1[0]) * (rec1[3] - rec1[1])\n",
    "        S2 = (rec2[2] - rec2[0]) * (rec2[3] - rec2[1])\n",
    "        S_cross = (down_row_min - up_row_max) * (right_column_min - left_column_max)\n",
    "        return S_cross / (S1 + S2 - S_cross)\n",
    "\n",
    "\n",
    "def face_zoom(area, ratio, width, height):  # area: 中心坐标，宽度，高度\n",
    "    [x, y, w, h] = area\n",
    "\n",
    "    w = w * ratio\n",
    "    h = h * ratio\n",
    "    x1 = max(x - w / 2, 0)\n",
    "    y1 = max(y - h / 2, 0)\n",
    "    x2 = min(x1 + w, 1)\n",
    "    y2 = min(y1 + h, 1)\n",
    "    bbox = [x1 * width, y1 * height, x2 * width, y2 * height]\n",
    "    return bbox  # 这里的bbox 还是浮点型，后续保存图片的时候同意转换\n",
    "    # return np.array(bbox).astype(int)\n",
    "    \n",
    "# 通过LightRoom人脸识别的方式，保存相关人脸信息\n",
    "def get_LM_face_info(img):\n",
    "    print(f'INFO: get_LM_face_info ... ')\n",
    "    num = 1  # xmp 内容下表从1开始\n",
    "    is_have_face = True\n",
    "\n",
    "    exiv_info = Image_pyexiv2(img.image.path)  # 登记图片路径\n",
    "    xmp = exiv_info.read_xmp()  # 读取元数据，这会返回一个字典\n",
    "    names = []\n",
    "    bboxs = []\n",
    "    while is_have_face:\n",
    "        print(f'INFO: LM face detected')\n",
    "        item = 'Xmp.mwg-rs.Regions/mwg-rs:RegionList[{:d}]/mwg-rs:Type'.format(num)\n",
    "        is_have_face = xmp.get(item)\n",
    "        if is_have_face:\n",
    "            idx_name = 'Xmp.mwg-rs.Regions/mwg-rs:RegionList[{:d}]/mwg-rs:Name'.format(num)\n",
    "            idx_h = 'Xmp.mwg-rs.Regions/mwg-rs:RegionList[{:d}]/mwg-rs:Area/stArea:h'.format(num)\n",
    "            idx_w = 'Xmp.mwg-rs.Regions/mwg-rs:RegionList[{:d}]/mwg-rs:Area/stArea:w'.format(num)\n",
    "            idx_x = 'Xmp.mwg-rs.Regions/mwg-rs:RegionList[{:d}]/mwg-rs:Area/stArea:x'.format(num)\n",
    "            idx_y = 'Xmp.mwg-rs.Regions/mwg-rs:RegionList[{:d}]/mwg-rs:Area/stArea:y'.format(num)\n",
    "            num += 1\n",
    "\n",
    "            name = xmp.get(idx_name, 'unknown')\n",
    "            names.append(name)\n",
    "            lm_face_area = [xmp.get(idx_x), xmp.get(idx_y), xmp.get(idx_w), xmp.get(idx_h)]  # 0~1 之间的字符\n",
    "            lm_face_area = np.array(lm_face_area).astype(float)  # 0~1 之间的浮点，中心区域，人脸长，宽\n",
    "            bbox = face_zoom(lm_face_area, 1, img.wid, img.height)  # 转变成像素值，左上区域和右下区域坐标，跟insightface 保持一致\n",
    "            bboxs.append(bbox)\n",
    "\n",
    "    return names, bboxs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54273f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: get_LM_face_info ... \n",
      "INFO: LM face detected\n",
      "INFO names is []\n",
      "INFO bboxs is []\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Blue/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Blue/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Blue/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Blue/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Blue/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     iou \u001b[38;5;241m=\u001b[39m compute_IOU(bbox, faces[i]\u001b[38;5;241m.\u001b[39mbbox)\n\u001b[0;32m     20\u001b[0m     ious \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(ious, iou)\n\u001b[1;32m---> 21\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[43mious\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m face_name \u001b[38;5;241m=\u001b[39m names[idx]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINFO ious is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mious\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "# 测试人脸及图片\n",
    "name='allison'\n",
    "face = Face.objects.filter(det_method=True, name=name).first()\n",
    "img=face.img\n",
    "\n",
    "\n",
    "names, bboxs = get_LM_face_info(img)\n",
    "print(f'INFO names is {names}')\n",
    "print(f'INFO bboxs is {bboxs}')\n",
    "\n",
    "app = FaceAnalysis(providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "image_path = img.image.path\n",
    "\n",
    "req_img = cv.imread(image_path)  # 自己用openCV进行读取\n",
    "cv.show(req_img)\n",
    "faces = app.get(req_img)\n",
    "# for i in range(len(faces)):\n",
    "#     ious=np.array([])\n",
    "#     for bbox in bboxs:\n",
    "#         iou = compute_IOU(bbox, faces[i].bbox)\n",
    "#         ious = np.append(ious, iou)\n",
    "#     idx = ious.argmax()\n",
    "#     face_name = names[idx]\n",
    "#     print(f'INFO ious is {ious}')\n",
    "#     print(f'estimated name is {face_name}, which is from LM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d21cca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "faces = get_people_fts('allison')\n",
    "print(type(faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a94237f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[1, 2, 3, 4], [3, 3, 3, 3]]\n",
      "2\n",
      "[1. 2. 3. 4. 3. 3. 3. 3.]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "a=[]\n",
    "print(len(a))\n",
    "b=[1,2,3,4]\n",
    "c=[3,3,3,3]\n",
    "a.append(b)\n",
    "a.append(c)\n",
    "print(a)\n",
    "print(len(a))\n",
    "a=[]\n",
    "a = np.append(a,b)\n",
    "a = np.append(a,c)\n",
    "print(a)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894b6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
